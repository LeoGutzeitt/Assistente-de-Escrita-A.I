# âœï¸ ASSISTENTE DE ESCRITA A.I

Uma aplicaÃ§Ã£o web inteligente que utiliza IA **100% GRATUITA** (Ollama) para corrigir erros, reescrever, melhorar e resumir textos em portuguÃªs.

## ğŸš€ FUNCIONALIDADES

- **âœ… CORREÃ‡ÃƒO DE TEXTO**: Corrige erros gramaticais, ortogrÃ¡ficos e de pontuaÃ§Ã£o
- **ğŸ”„ REESCRITA DE TEXTO**: Reescreve em 4 estilos (formal, informal, tÃ©cnico, criativo)
- **â¬†ï¸ MELHORIA DE TEXTO**: Aprimora qualidade, clareza e coesÃ£o
- **ğŸ“ RESUMO DE TEXTO**: Gera resumos em 3 tamanhos (curto, mÃ©dio, longo)
- **ğŸ’¡ SUGESTÃ•ES DE MELHORIA**: Analisa e sugere melhorias sem reescrever
- **ğŸ¨ INTERFACE YOUTUBE**: Design escuro moderno com navegaÃ§Ã£o por sidebar
- **ğŸ†“ TOTALMENTE GRATUITO**: Sem API keys, sem custos, 100% local

## ğŸ“‹ PRÃ‰-REQUISITOS

- **Python 3.8+**
- **Ollama** (IA local e gratuita)
- **Navegador web moderno**

## ğŸ”§ INSTALAÃ‡ÃƒO

### 1ï¸âƒ£ INSTALAR OLLAMA (IA Gratuita)

**Windows:**

1. Baixe: https://ollama.com/download/windows
2. Execute o instalador `.exe`
3. Reinicie o terminal apÃ³s instalaÃ§Ã£o

**Linux:**

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

**macOS:**

1. Baixe: https://ollama.com/download/mac
2. Arraste para Aplicativos

### 2ï¸âƒ£ BAIXAR MODELO DE IA

Abra um terminal e execute:

```bash
ollama pull llama3.2
```

Aguarde o download (~2GB). Modelos alternativos: `mistral`, `gemma`, `phi3`

### 3ï¸âƒ£ CONFIGURAR BACKEND (Flask)

1. Clone o repositÃ³rio e navegue atÃ© a pasta backend:

```bash
cd backend
```

2. Crie e ative ambiente virtual:

```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# Linux/Mac
python3 -m venv .venv
source .venv/bin/activate
```

3. Instale dependÃªncias:

```bash
pip install -r requirements.txt
```

4. **(OPCIONAL)** Configure variÃ¡veis de ambiente `.env`:

```env
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
```

### 4ï¸âƒ£ EXECUTAR APLICAÃ‡ÃƒO

**Terminal 1 - Iniciar Ollama:**

```bash
ollama serve
```

**Terminal 2 - Iniciar Flask:**

```bash
cd backend
python app.py
```

Acesse: **http://localhost:5000**

## ğŸ¯ COMO USAR

1. Acesse **http://localhost:5000** no navegador
2. Digite ou cole seu texto no editor
3. Use a **BARRA LATERAL** para navegar entre funcionalidades:
   - **ğŸ“ EDITOR**: Ãrea de ediÃ§Ã£o principal
   - **âœ… CORRIGIR**: Corrige erros gramaticais
   - **ğŸ”„ REESCREVER**: Escolha estilo (formal/informal/tÃ©cnico/criativo)
   - **â¬†ï¸ MELHORAR**: Aprimora qualidade geral
   - **ğŸ“ RESUMIR**: Gera resumo (curto/mÃ©dio/longo)
   - **ğŸ’¡ SUGESTÃ•ES**: Recebe anÃ¡lise e sugestÃµes
4. O resultado aparece no painel direito
5. Use botÃµes **COPIAR** ou **SUBSTITUIR** para gerenciar resultados

## ğŸ› ï¸ TECNOLOGIAS UTILIZADAS

- **Backend**: Flask 3.0.0, Python 3.x
- **IA**: Ollama (llama3.2 - 100% gratuito e local)
- **Frontend**: HTML5, CSS3, JavaScript Vanilla
- **Design**: Material Icons, Dark Theme (YouTube-inspired)
- **API**: RESTful com JSON

## ğŸ“ ESTRUTURA DO PROJETO

```
Assistente-de-Escrita-A.I/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                 # Flask API + servidor estÃ¡tico
â”‚   â”œâ”€â”€ requirements.txt       # DependÃªncias Python
â”‚   â”œâ”€â”€ .env.example          # Template de configuraÃ§Ã£o
â”‚   â””â”€â”€ .gitignore
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index_novo.html       # Interface YouTube-style
â”‚   â”œâ”€â”€ style_novo.css        # Dark theme (preto/azul)
â”‚   â””â”€â”€ script_novo.js        # LÃ³gica e API calls
â”œâ”€â”€ INSTALL_OLLAMA.md         # Guia detalhado de instalaÃ§Ã£o
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

## ğŸ› SOLUÃ‡ÃƒO DE PROBLEMAS

### Erro HTTP 500

âœ… Verifique se o Ollama estÃ¡ rodando: `ollama serve`
âœ… Verifique se o modelo estÃ¡ instalado: `ollama list`
âœ… Baixe o modelo se necessÃ¡rio: `ollama pull llama3.2`

### "Ollama nÃ£o estÃ¡ rodando"

âœ… Abra terminal separado e execute: `ollama serve`
âœ… Mantenha este terminal aberto durante o uso

### PÃ¡gina nÃ£o carrega

âœ… Verifique se Flask estÃ¡ rodando: `python app.py`
âœ… Acesse: http://localhost:5000 (nÃ£o http://127.0.0.1:5000)

### Resposta muito lenta

âœ… Use modelo menor: `ollama pull phi3`
âœ… Altere no `.env`: `OLLAMA_MODEL=phi3`
âœ… Reinicie o Flask

## ğŸ“ ENDPOINTS DA API

- `GET /api/health` - Status da API
- `POST /api/corrigir` - Corrige texto
- `POST /api/reescrever` - Reescreve em estilo especÃ­fico
- `POST /api/melhorar` - Melhora qualidade
- `POST /api/resumir` - Gera resumo
- `POST /api/sugestoes` - Analisa e sugere
- `POST /api/verificar-plagio` - (Em desenvolvimento)

## ğŸš€ PRÃ“XIMAS MELHORIAS

- [ ] Sistema de histÃ³rico com banco de dados
- [ ] ExportaÃ§Ã£o em PDF/DOCX
- [ ] AnÃ¡lise de mÃ©tricas (palavras, frases, legibilidade)
- [ ] DetecÃ§Ã£o de plÃ¡gio (API externa)
- [ ] Tema claro/escuro
- [ ] AutenticaÃ§Ã£o de usuÃ¡rios
- [ ] Cache de respostas (Redis)

## ğŸ“„ LICENÃ‡A

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## ğŸ‘¤ AUTOR

**Project BitBloom**

---

â­ **Dica**: Para melhor desempenho, use SSD e pelo menos 8GB de RAM. O modelo `llama3.2` requer ~2GB de espaÃ§o em disco.

## ğŸ” SeguranÃ§a

- **Nunca compartilhe sua API key**
- O arquivo `.env` estÃ¡ no `.gitignore` para evitar commits acidentais
- Use variÃ¡veis de ambiente para configuraÃ§Ãµes sensÃ­veis

## ğŸ“ Notas

- A qualidade dos resultados depende do modelo de IA utilizado
- VocÃª pode ajustar os parÃ¢metros de temperatura nos prompts para resultados diferentes
- Ã‰ possÃ­vel adaptar o cÃ³digo para usar outras APIs de IA (Azure OpenAI, Anthropic, etc.)

## ğŸ¤ Contribuindo

Sinta-se Ã  vontade para abrir issues e pull requests!

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.
